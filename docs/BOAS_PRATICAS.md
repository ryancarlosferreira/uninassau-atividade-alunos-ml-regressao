# Guia de Boas Pr√°ticas - Projeto ML

## üìã √çndice
1. [Organiza√ß√£o de C√≥digo](#organiza√ß√£o-de-c√≥digo)
2. [Controle de Vers√£o (Git)](#controle-de-vers√£o)
3. [Notebooks Jupyter](#notebooks-jupyter)
4. [Documenta√ß√£o](#documenta√ß√£o)
5. [Trabalho em Equipe](#trabalho-em-equipe)
6. [Machine Learning](#machine-learning)

---

## üóÇÔ∏è Organiza√ß√£o de C√≥digo

### Estrutura de Diret√≥rios
```
projeto/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/           # Dados originais (nunca modificar)
‚îÇ   ‚îú‚îÄ‚îÄ processed/     # Dados processados
‚îÇ   ‚îî‚îÄ‚îÄ external/      # Dados de fontes externas
‚îú‚îÄ‚îÄ notebooks/         # Jupyter notebooks
‚îú‚îÄ‚îÄ src/              # C√≥digo Python reutiliz√°vel
‚îú‚îÄ‚îÄ models/           # Modelos treinados
‚îú‚îÄ‚îÄ reports/          # Relat√≥rios e figuras
‚îÇ   ‚îî‚îÄ‚îÄ figures/
‚îú‚îÄ‚îÄ scripts/          # Scripts execut√°veis
‚îî‚îÄ‚îÄ tests/            # Testes (opcional)
```

### Nomea√ß√£o de Arquivos
‚úÖ **BOM:**
- `etapa1_eda.ipynb`
- `preprocessing_utils.py`
- `model_random_forest_v2.pkl`

‚ùå **RUIM:**
- `Untitled1.ipynb`
- `teste.py`
- `final_final_v3_agora_vai.pkl`

### Estilo de C√≥digo Python (PEP 8)

```python
# ‚úÖ BOM
import pandas as pd
import numpy as np

def calculate_mean_score(scores):
    """Calcula a m√©dia dos scores.

    Args:
        scores (list): Lista de scores

    Returns:
        float: M√©dia dos scores
    """
    return np.mean(scores)

# Nome de vari√°vel descritivo
student_mean_grade = calculate_mean_score([85, 90, 78])

# ‚ùå RUIM
import pandas as pd,numpy as np

def calc(s):
    return np.mean(s)

x=calc([85,90,78])
```

---

## üîÑ Controle de Vers√£o (Git)

### Commits

#### Mensagens de Commit
‚úÖ **BOM:**
```bash
git commit -m "feat: adiciona an√°lise de correla√ß√£o no EDA"
git commit -m "fix: corrige tratamento de valores faltantes"
git commit -m "docs: atualiza README com instru√ß√µes de instala√ß√£o"
```

‚ùå **RUIM:**
```bash
git commit -m "mudan√ßas"
git commit -m "atualizando"
git commit -m "asdfasdf"
```

#### Prefixos Recomendados
- `feat:` - Nova funcionalidade
- `fix:` - Corre√ß√£o de bug
- `docs:` - Documenta√ß√£o
- `style:` - Formata√ß√£o de c√≥digo
- `refactor:` - Refatora√ß√£o
- `test:` - Testes
- `chore:` - Tarefas de manuten√ß√£o

### Workflow Git

```bash
# 1. Criar branch para feature
git checkout -b feat/data-preprocessing

# 2. Fazer mudan√ßas e commits
git add src/preprocessing.py
git commit -m "feat: adiciona fun√ß√£o de normaliza√ß√£o"

# 3. Push para remoto
git push origin feat/data-preprocessing

# 4. Abrir Pull Request no GitHub

# 5. Ap√≥s aprova√ß√£o, merge na main
```

### .gitignore Essencial

```gitignore
# Python
__pycache__/
*.py[cod]
.Python
venv/
env/

# Jupyter
.ipynb_checkpoints/

# Data (se grande)
data/raw/*.csv
!data/raw/sample.csv  # Exceto sample

# Models (se grande)
models/*.pkl

# IDE
.vscode/
.idea/

# OS
.DS_Store
```

---

## üìì Notebooks Jupyter

### Estrutura de Notebook

```markdown
# T√≠tulo do Notebook - Etapa X

**Autor:** [Nome]
**Data:** [DD/MM/YYYY]
**Vers√£o:** 1.0

## √çndice
1. [Importa√ß√µes](#imports)
2. [Carregamento de Dados](#load-data)
3. [An√°lise Explorat√≥ria](#eda)
4. [Conclus√µes](#conclusions)
```

### C√©lulas de C√≥digo

```python
# ‚úÖ BOM: C√©lula organizada com coment√°rios
# Carregar e inspecionar dataset
df = pd.read_csv('data/raw/students.csv')
print(f"Shape: {df.shape}")
print(f"Colunas: {df.columns.tolist()}")
df.head()
```

```python
# ‚ùå RUIM: C√©lula desorganizada
df=pd.read_csv('data/raw/students.csv')
df.head()
df.shape
df.columns
df.info()
df.describe()
# ... muitas opera√ß√µes em uma c√©lula
```

### Cells Markdown

Use markdown para explicar:
- **O que** voc√™ est√° fazendo
- **Por que** est√° fazendo
- **O que** voc√™ descobriu

```markdown
## An√°lise de Correla√ß√£o

Vamos investigar a correla√ß√£o entre horas de estudo e nota final.
Esperamos uma correla√ß√£o positiva, pois mais estudo geralmente
leva a melhores resultados.
```

### Visualiza√ß√µes

```python
# ‚úÖ BOM: Visualiza√ß√£o completa
plt.figure(figsize=(10, 6))
plt.scatter(df['study_hours'], df['final_grade'], alpha=0.5)
plt.xlabel('Horas de Estudo por Semana')
plt.ylabel('Nota Final')
plt.title('Rela√ß√£o entre Horas de Estudo e Nota Final')
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.savefig('reports/figures/study_vs_grade.png', dpi=300)
plt.show()
```

### Antes de Fazer Commit

```bash
# 1. Limpar outputs (para reduzir tamanho)
# No Jupyter: Cell > All Output > Clear

# 2. Restart & Run All
# Garantir que notebook executa do in√≠cio ao fim

# 3. Salvar
# File > Save and Checkpoint
```

---

## üìö Documenta√ß√£o

### Docstrings

```python
def preprocess_data(df, strategy='mean'):
    """
    Pr√©-processa o dataset de estudantes.

    Aplica as seguintes transforma√ß√µes:
    - Tratamento de valores faltantes
    - Codifica√ß√£o de vari√°veis categ√≥ricas
    - Normaliza√ß√£o de features num√©ricas

    Parameters
    ----------
    df : pd.DataFrame
        Dataset bruto
    strategy : str, optional
        Estrat√©gia de imputa√ß√£o ('mean', 'median', 'mode')
        Default: 'mean'

    Returns
    -------
    pd.DataFrame
        Dataset processado

    Examples
    --------
    >>> df_clean = preprocess_data(df, strategy='median')
    >>> df_clean.shape
    (2000, 15)
    """
    # Implementa√ß√£o
    pass
```

### README.md

```markdown
# Nome do Projeto

## Descri√ß√£o
[Breve descri√ß√£o]

## Instala√ß√£o
\`\`\`bash
pip install -r requirements.txt
\`\`\`

## Uso
\`\`\`python
python scripts/predict.py --input data.csv
\`\`\`

## Estrutura
[Explicar estrutura de diret√≥rios]

## Contribuidores
- [Nome 1]
- [Nome 2]
```

---

## üë• Trabalho em Equipe

### Divis√£o de Tarefas

| Membro | Responsabilidade Principal | Backup |
|--------|---------------------------|---------|
| Alice | EDA e Visualiza√ß√µes | Feature Engineering |
| Bob | Pr√©-processamento | Modelagem |
| Carol | Modelagem e Otimiza√ß√£o | Documenta√ß√£o |
| Dave | Documenta√ß√£o e Deploy | Pr√©-processamento |

### Comunica√ß√£o

- **Daily Standup:** Reuni√£o r√°pida di√°ria (15 min)
  - O que fiz ontem?
  - O que farei hoje?
  - H√° bloqueios?

- **Code Review:** Sempre revisar PRs dos colegas
  - Verificar l√≥gica
  - Sugerir melhorias
  - Aprovar ou solicitar mudan√ßas

- **Issues no GitHub:**
  ```markdown
  **T√≠tulo:** Implementar valida√ß√£o cruzada

  **Descri√ß√£o:**
  Precisamos implementar K-Fold CV nos top 3 modelos.

  **Tarefas:**
  - [ ] Implementar CV para Random Forest
  - [ ] Implementar CV para XGBoost
  - [ ] Implementar CV para LightGBM
  - [ ] Visualizar resultados

  **Respons√°vel:** @bob
  **Prazo:** 15/02/2025
  ```

### Pull Requests

```markdown
## Descri√ß√£o
Adiciona an√°lise de import√¢ncia de features usando SHAP values.

## Mudan√ßas
- Instala biblioteca shap
- Cria notebook com an√°lise SHAP
- Adiciona visualiza√ß√µes de import√¢ncia

## Checklist
- [x] C√≥digo testado
- [x] Documenta√ß√£o atualizada
- [x] Notebook executa
- [ ] Aprovado por revisor

## Screenshots
[Incluir imagem da visualiza√ß√£o SHAP]
```

---

## ü§ñ Machine Learning

### Data Leakage - CUIDADO!

‚ùå **NUNCA FA√áA ISSO:**
```python
# ERRADO: Normalizar antes de dividir
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)  # Usou TODOS os dados!
X_train, X_test = train_test_split(X_scaled, ...)
```

‚úÖ **CORRETO:**
```python
# Primeiro dividir, depois normalizar
X_train, X_test = train_test_split(X, ...)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)  # Fit s√≥ no treino
X_test_scaled = scaler.transform(X_test)        # Transform no teste
```

### Reprodutibilidade

```python
# Sempre use random_state para reprodutibilidade
import numpy as np
import random

# Seeds
SEED = 42
np.random.seed(SEED)
random.seed(SEED)

# Em train_test_split
X_train, X_test = train_test_split(X, y, random_state=SEED)

# Em modelos
model = RandomForestRegressor(random_state=SEED)
```

### Salvando Modelos

```python
import joblib

# Salvar modelo e scaler
joblib.dump(model, 'models/random_forest_v1.pkl')
joblib.dump(scaler, 'models/scaler_v1.pkl')

# Carregar
model = joblib.load('models/random_forest_v1.pkl')
scaler = joblib.load('models/scaler_v1.pkl')
```

### Valida√ß√£o

```python
# ‚úÖ BOM: Sempre validar em dados separados
from sklearn.model_selection import cross_val_score

# Treino/Valida√ß√£o/Teste
X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2)
X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25)

# Cross-validation no treino
scores = cross_val_score(model, X_train, y_train, cv=5)

# Avaliar no teste APENAS no final
y_pred = model.predict(X_test)
```

---

## üìä Visualiza√ß√µes

### Configura√ß√£o Padr√£o

```python
import matplotlib.pyplot as plt
import seaborn as sns

# Configura√ß√£o global
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")
plt.rcParams['figure.figsize'] = (10, 6)
plt.rcParams['font.size'] = 12
```

### Template de Gr√°fico

```python
def plot_distribution(data, column, title=None):
    """Plota distribui√ß√£o de uma vari√°vel."""
    fig, axes = plt.subplots(1, 2, figsize=(14, 5))

    # Histograma
    axes[0].hist(data[column], bins=30, edgecolor='black')
    axes[0].set_xlabel(column)
    axes[0].set_ylabel('Frequ√™ncia')
    axes[0].set_title(f'Distribui√ß√£o de {column}')

    # Boxplot
    axes[1].boxplot(data[column].dropna())
    axes[1].set_ylabel(column)
    axes[1].set_title(f'Boxplot de {column}')

    plt.tight_layout()

    if title:
        plt.savefig(f'reports/figures/{title}.png', dpi=300, bbox_inches='tight')

    plt.show()
```

---

## ‚úÖ Checklist Antes de Entregar

### C√≥digo
- [ ] Notebook executa do in√≠cio ao fim
- [ ] Sem c√©lulas com erros
- [ ] C√≥digo comentado
- [ ] Segue PEP 8

### Git
- [ ] Commits descritivos
- [ ] .gitignore configurado
- [ ] README atualizado
- [ ] Tag de vers√£o criada

### Documenta√ß√£o
- [ ] Relat√≥rio completo
- [ ] Docstrings nas fun√ß√µes
- [ ] Visualiza√ß√µes salvas
- [ ] Resultados documentados

### Machine Learning
- [ ] Sem data leakage
- [ ] Seeds definidos
- [ ] Modelos salvos
- [ ] M√©tricas documentadas

---

## üìö Recursos Adicionais

### Livros
- "Python for Data Analysis" - Wes McKinney
- "Hands-On Machine Learning" - Aur√©lien G√©ron

### Cursos Online
- [Kaggle Learn](https://www.kaggle.com/learn)
- [Fast.ai](https://www.fast.ai/)

### Ferramentas
- [GitHub Desktop](https://desktop.github.com/)
- [VS Code](https://code.visualstudio.com/)
- [JupyterLab](https://jupyter.org/)

---

**√öltima atualiza√ß√£o:** Janeiro 2025
